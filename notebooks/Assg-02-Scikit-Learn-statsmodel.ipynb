{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 02: Scikit Learn Basic Regression and Classification\n",
    "\n",
    "**Due Date:** Friday 09/20/2024 (5pm) \n",
    "\n",
    "**Please fill these in before submitting, just in case I accidentally mix up file names while grading**:\n",
    "\n",
    "Name: Jane Student\n",
    "\n",
    "CWID-5: (Last 5 digits of cwid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "--------\n",
    "\n",
    "In this exercise we will be performing a regression and classification task using the `scikit-learn` machine learning framework, and the Python `statsmodel` library.\n",
    "You should work through the tutorial on using `scikit-learn` and `statsmodel` before doing this assignment, as well as work on the materials from our units\n",
    "on regression and classification tasks.\n",
    "\n",
    "For the first part of this assignment, I recommend looking through the following tutorials on using\n",
    "Scikit Learn and the statsmodel library for linear regression:\n",
    "\n",
    "[A Beginners guide to Linear Regression in Python with Scikit-Learn](https://medium.com/analytics-vidhya/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-6b0fe70b32d7)\n",
    "\n",
    "\n",
    "[Use statsmodels to Perform Linear Regression in Python](https://datatofish.com/statsmodels-linear-regression/)\n",
    "\n",
    "I am using this material as a reference when developing the work and questions for the first Task 1 of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T18:55:15.339855Z",
     "start_time": "2019-09-30T18:55:14.517211Z"
    }
   },
   "outputs": [],
   "source": [
    "# all imports that you use for this assignment should be placed here in the first cell to execute\n",
    "# if you need something not imported for you, add the import here for your assignment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# By convention, we often just import the specific classes/functions in notebooks\n",
    "# from scikit-learn we will need to train a model and perform prediction.\n",
    "# You will probably need more stuff imported here and in your test script files\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# statsmodels has an api, it is often imported as sm by convention\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions/moduls from this project.  We manually set the\n",
    "# PYTHONPATH to append the location to search for this assignments\n",
    "# functions to just ensure the imports are found\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# assignment function imports for doctests and github autograding\n",
    "# these are required for assignment autograding\n",
    "from AssgUtils import run_doctests\n",
    "from Task1sklearn import task1_sklearn\n",
    "from Task1statsmodel import task1_statsmodel\n",
    "from Task2labeltests import task2_label_tests\n",
    "from Task2featuretests import task2_feature_tests\n",
    "from Task2sklearn import task2_sklearn\n",
    "from Task2statsmodel import task2_statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T18:55:15.345630Z",
     "start_time": "2019-09-30T18:55:15.341203Z"
    }
   },
   "outputs": [],
   "source": [
    "# set default figure size, 8in by 6in and figure properties here for this notebook,\n",
    "# please don't change these in final submission of your work\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Linear Regression with One Variable\n",
    "--------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data\n",
    "\n",
    "There is a file named `assg-02-weather.csv` in the data subdirectory.  Load this file into a\n",
    "pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file into a dataframe here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some basic data exploration.  Perform the following tasks:\n",
    "\n",
    "1. Determine the number of samples in this data set.  Determine the number of features as well.\n",
    "2. Display the types of the features that were read in and determined by default by Pandas in this dataframe.\n",
    "3. For the numeric data types, describe the basic information about the min, max and ranges of the numeric data\n",
    "4. Count the number of missing or NaN data in the dataframe (if any), show the counts of missing data for each of the features in the dataframe.\n",
    "5. It will be useful to know the feature to feature correlations.  Create and display a correlation matrix of the numeric features\n",
    "   in this dataset.  You will need to extract into a temporary dataframe the numeric features to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. determine number of samples and number of features here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. determine feature types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. display basic information about the range of numeric features in the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. determine if there is any missing data in the dataset, show counts of missing data for each feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. show feature-to-feature correlation of the numeric features we currently have in this data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "We will try and create a linear regression model of the relationship between temperature and\n",
    "evaporation.  There are several temperature measurements in this dataset.  \n",
    "\n",
    "1. Using base matplotlib, create a scatter plot the relationship between\n",
    "   the `Temp9am` and `Evaporation` recorded values.\n",
    "   The temperature should be the independent variable (x axis) and evaporation measurement the dependent\n",
    "   variable (y axis) in this plot.  Label your axis, you weren't given a data dictionary but\n",
    "   see if you can figure out the likely units used to record temperature and evaporation in this data\n",
    "   and label the axes accordingly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot here to visualize the relation between the feature and the label we want to predict\n",
    "# don't forget to label your axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Evaluate a Scikit-learn LinearRegression Model\n",
    "\n",
    "We will fit a linear regression model, first using the scikit-learn framework.\n",
    "\n",
    "Create a LinearRegression model and fit all of the 9am temperature data (independent variable) to try and\n",
    "predict evaporation (dependent variable). Perform the following tasks\n",
    "\n",
    "1. You need to define a feature array `X` and a regression label array `y` for the regression data before the\n",
    "   doctest function is called.\n",
    "2. Fit a scikit-learn LinearRegression to the 9am temperature data to predict evaporation.  Use all default metaparameter\n",
    "   values, do not change any of the default settings for the scikit-learn linear regression.\n",
    "   - You need to implement the creation of the model in the `task1_sklearn()` function (found in `src/Task1sklearn.py`.  This function should fit\n",
    "     the described model and reutrn it along with the fitted `intercept, slope, mse, rmse, rsquared` values in order\n",
    "     to pass all of the doctests that are performed.\n",
    "   - You need to extact the 9am temperature data into an array/series called `X` and the evaporation dependent variable into a variable\n",
    "     named `y` to be passed into the function where you create your model and report the model fit parameters.\n",
    "3. Inside of the function you write, you need to extract and return the fitted model parameters that are tested.\n",
    "   Extract and return the slope and intercept coefficients you obtained when fitting this model.\n",
    "4. Extract and return the RMSE error total of this model on all of the data it was fitted with.\n",
    "5. Extract and return the R^2 score of this fitted model.  The R^2 score is related to but slightly different from\n",
    "   the RMSE.\n",
    "6. Replot the scatter plot of your data.  But show the fitted line from the linear regression on the model.\n",
    "   Label the axis the same as before.  But this time include a legend.  Make sure the data is plotted as scatter\n",
    "   plot points and identified as suche in the figure.  Also plot the model as a line and identify it in the legend.\n",
    "   Make your figure look like the following.  The regression model line you obtain should\n",
    "   (exactly) match the one shown in this figure.\n",
    "\n",
    "![Regression Model Result](../figures/assg-02-regression-result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. extract/create feature array X and regression label y, replace the dummy\n",
    "# initializations with correct ones before calling the test function with them\n",
    "X = np.zeros((4, 1))\n",
    "y = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in task1_sklearn\n",
      "Trying:\n",
      "    from AssgUtils import isclose\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    model, intercept, slopes, mse, rmse, rsquared = task1_sklearn(X, y)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    isclose(intercept, 0.37578175021210747)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task1sklearn.py\", line 32, in task1_sklearn\n",
      "Failed example:\n",
      "    isclose(intercept, 0.37578175021210747)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 0.375782 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(slopes[0], 0.3354845860060065)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task1sklearn.py\", line 34, in task1_sklearn\n",
      "Failed example:\n",
      "    isclose(slopes[0], 0.3354845860060065)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 0.335485 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(mse, 3.5473465427798607)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task1sklearn.py\", line 36, in task1_sklearn\n",
      "Failed example:\n",
      "    isclose(mse, 3.5473465427798607)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 3.547347 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(rmse, 1.8834400820784984)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task1sklearn.py\", line 38, in task1_sklearn\n",
      "Failed example:\n",
      "    isclose(rmse, 1.8834400820784984)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 1.883440 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(rsquared, 0.5008050204985712)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task1sklearn.py\", line 40, in task1_sklearn\n",
      "Failed example:\n",
      "    isclose(rsquared, 0.5008050204985712)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 0.500805 but actual value 0.000000'\n"
     ]
    }
   ],
   "source": [
    "# 2. fit scikit-learn LinearRegression to the temperature / evaporation data\n",
    "\n",
    "# your work should go into the src/Task2sklearn function named task1_sklearn()\n",
    "# This cell must not be removed or modified, it calls your function to create a model and\n",
    "# return the fitted parameters from the regression, and it runs doctests to see if your\n",
    "# model fit matches the expected fit you should get\n",
    "model, intercept, slopes, mse, rmse, rsquared = task1_sklearn(X, y)\n",
    "\n",
    "# run the doc tests so you can see if your fitted model got the expected results\n",
    "# if any of these tests do not pass (don't get ok result) you have done something\n",
    "# wrong in creating your data and/or fitting your model and extracting the\n",
    "# fit parameters\n",
    "run_doctests(task1_sklearn, globals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model intercept term:  0\n",
      "Model slope term:      0.0\n",
      "MSE :  0\n",
      "RMSE:  0\n",
      "R^2 score:  0\n"
     ]
    }
   ],
   "source": [
    "# You don't have to do anything here, these will display the model fit parameters\n",
    "# you return from your function.  You can compare your parameters and results to\n",
    "# the expected doctest results you should obtain\n",
    "\n",
    "# 3. return the slope and intercept coefficients of the fitted model\n",
    "print('Model intercept term: ', intercept)\n",
    "print('Model slope term:     ', slopes[0])\n",
    "\n",
    "# 4. return and report the RMSE error obtained on this model with all of the data we used to fit the model\n",
    "# example using scikit-learn method as shown in text/lecture notebooks\n",
    "print('MSE : ', mse)\n",
    "print('RMSE: ', rmse)\n",
    "\n",
    "# 5. return and report the R^2 score of this fit. \n",
    "print('R^2 score: ', rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. replot scatter plot of data adding in fitted regression model line to plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Evaluate a statsmodel ordinary least squares Model\n",
    "\n",
    "For comparison, you will next use the statsmodel library to perform a linear regression on the same\n",
    "independent variable (temperature at 9am) to predict evaporation.  Perform the\n",
    "following tasks.\n",
    "\n",
    "1. Create and fit a statsmodel OLS (ordinary least squared) regression of the data.  You will need\n",
    "   to correctly use the statsmodel API here as discussed.  Also don't forget that, for reasons, you\n",
    "   will need to create a dummy intercept term for your input data for the statsmodel OLS\n",
    "   - You need to implement the creation of the model in the `task1_statsmodel()` function (found in `src/Task1statsmodel.py`.  This function should fit\n",
    "     the described model and reutrn it along with the fitted `params, rsquared` values in order\n",
    "     to pass all of the doctests that are performed.\n",
    "   - You extracted the input feature `X` and the target variable `y` before.  You should pass in the same `X` used before, but inside of your function,\n",
    "     before you create and fit your statsmodel, remember that you will need to add in the dummy constant to `X` by hand, as we should have discussed in\n",
    "     class and as is discussed in some of the materials and tutorial you should have looke at.\n",
    "2. Determine the intercept and slope coefficients from the summary (you only need to find and return the OLS params that holds all of these coefficients).\n",
    "   Determine the R^2 score from the model and return it.  These should exactly match the expected results from the doctests if the model is created and fit\n",
    "   correctly.\n",
    "3. Use the statsmodel summary function to display this same information (and more) about the fitted model that is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in task1_statsmodel\n",
      "Trying:\n",
      "    from AssgUtils import isclose\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    model, params, rsquared = task1_statsmodel(y, X)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    isclose(params[0], 0.37578175021210747)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task1statsmodel.py\", line 35, in task1_statsmodel\n",
      "Failed example:\n",
      "    isclose(params[0], 0.37578175021210747)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 0.375782 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(params[1], 0.3354845860060065)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task1statsmodel.py\", line 37, in task1_statsmodel\n",
      "Failed example:\n",
      "    isclose(params[1], 0.3354845860060065)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 0.335485 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(rsquared, 0.5008050204985712)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task1statsmodel.py\", line 39, in task1_statsmodel\n",
      "Failed example:\n",
      "    isclose(rsquared, 0.5008050204985712)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 0.500805 but actual value 0.000000'\n"
     ]
    }
   ],
   "source": [
    "# 1. Create and fit a statsmodel OLS regression\n",
    "\n",
    "# your work should go into the src/Task1statsmodel function named task1_statsmodel()\n",
    "# This cell must not be removed or modified, it calls your function to create a model and\n",
    "# return the fitted parameters from the regression, and it runs doctests to see if your\n",
    "# model fit matches the expected fit you should get\n",
    "model, params, rsquared = task1_statsmodel(y, X)\n",
    "\n",
    "# run the doc tests so you can see if your fitted model got the expected results\n",
    "# if any of these tests do not pass (don't get ok result) you have done something\n",
    "# wrong in creating your data and/or fitting your model and extracting the\n",
    "# fit parameters\n",
    "run_doctests(task1_statsmodel, globals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model intercept term:  0.0\n",
      "Model slope term:      0.0\n",
      "Model R^2 score:       0\n"
     ]
    }
   ],
   "source": [
    "# 2. Determine the model parameter slope and intercept terms as well as the rsquared fit result\n",
    "# and return these along with the model.  You don't have to do anything in this cell, the\n",
    "# returned parameters displayed should match the expected values for the doctests\n",
    "print('Model intercept term: ', params[0])\n",
    "print('Model slope term:     ', params[1])\n",
    "print('Model R^2 score:      ', rsquared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. display summary information about the statsmodel OLS linear regression model fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown here, the fitted model parameters and $R^2$ score both should exactly match\n",
    "the results obtained by scikit-learn when fitting using default linear regression.  We\n",
    "can see further information about the fit from the statsmodel summary.  The p-value and interval\n",
    "given for the const and x1 parameters show the 95% confidence interval of the fitted coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Binary Classification using Logistic Classifier\n",
    "--------\n",
    "\n",
    "## Encode Categorical Variables\n",
    "\n",
    "The weather dataset you were given contains several categorical variables.  We will try and build\n",
    "a binary classifier on the `RainTomorrow` attribute.  Do the following tasks\n",
    "\n",
    "1. Confirm that the rain tomorrow attribute is in fact a binary categorical variable. For example, use\n",
    "   methods to determine all of the unique values and count how many of each you have for that attribute.\n",
    "2. Create a simple pipeline to encode the rain tomorrow attribute as ordinal (integer) values.  Make sure \n",
    "   that \"no\" rain tomorrow is encoded as the false or 0 value, and \"yes\" rain tomorrow\n",
    "   is encoded as the true or 1 value.\n",
    "3. Encode the rain tomorrow as a categorical variable.  Save the results in a dataframe or numpy array\n",
    "   (you will need to call it `y` again for the doctests) to use as the target values for training.\n",
    "4. To double check, verify that no is encoded as 0 or false and yes as 1 or true after you encode the\n",
    "   categorical variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. verify that the rain tomorrow string attribute is a binary categorical variable by\n",
    "#    determining all unique categories and counting the number of each unique category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. create ordinal encoder pipeline to encode the rain tomorrow attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. encode the rain tomorrow as categorical variables and save result in array\n",
    "#    array y or labels for training, you should replace this with your encode `y`\n",
    "y = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. double check that no is encoded as 0 and yes as 1 in ordinal encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test that you performed the encoding correctly, your `y` will be passed through the\n",
    "`task2_label_tests()` doctests to see if the expected types and encodings have been\n",
    "as described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in task2_label_tests\n",
      "Trying:\n",
      "    ndim, shape, num_no, num_yes = task2_label_tests(y)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    ndim\n",
      "Expecting:\n",
      "    1\n",
      "ok\n",
      "Trying:\n",
      "    shape\n",
      "Expecting:\n",
      "    (366,)\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2labeltests.py\", line 31, in task2_label_tests\n",
      "Failed example:\n",
      "    shape\n",
      "Expected:\n",
      "    (366,)\n",
      "Got:\n",
      "    (4,)\n",
      "Trying:\n",
      "    num_no\n",
      "Expecting:\n",
      "    300\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2labeltests.py\", line 33, in task2_label_tests\n",
      "Failed example:\n",
      "    num_no\n",
      "Expected:\n",
      "    300\n",
      "Got:\n",
      "    4\n",
      "Trying:\n",
      "    num_yes\n",
      "Expecting:\n",
      "    66\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2labeltests.py\", line 35, in task2_label_tests\n",
      "Failed example:\n",
      "    num_yes\n",
      "Expected:\n",
      "    66\n",
      "Got:\n",
      "    0\n"
     ]
    }
   ],
   "source": [
    "# For this test, you just need to create the y labels correctly as\n",
    "# described before they are tested here\n",
    "ndim, shape, num_no, num_yes = task2_label_tests(y)\n",
    "\n",
    "# run the doc tests so you can see the encoded categorical labels are as expected\n",
    "run_doctests(task2_label_tests, globals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label number of dimensions:  1\n",
      "Label shape               :  (4,)\n",
      "Label number of no labels :  4\n",
      "Label number of yes labels:  0\n"
     ]
    }
   ],
   "source": [
    "print('Label number of dimensions: ', ndim)\n",
    "print('Label shape               : ', shape)\n",
    "print('Label number of no labels : ', num_no)\n",
    "print('Label number of yes labels: ', num_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Missing Data\n",
    "\n",
    "We will be using the `Sunshine` and `Pressure3pm` attributes when building a classifier.\n",
    "There are some missing values in one of these attributes.\n",
    "\n",
    "1. Create a new dataframe or numpy array with only 2 features/columns, the `Sunshine`\n",
    "   and `Pressure3pm` attributes.\n",
    "2. Determine the number of missing values in each of the two attributes `Sunshine` and `Pressure3pm`\n",
    "3. Create a simple imputer that will fill in missing values with\n",
    "   the mean value of that attribute\n",
    "4. Fit the imputer and use it to fill in missing values in your dataframe with only\n",
    "   the two attributes we will use.\n",
    "5. Confirm that there are no longer any missing values in the dataframe/numpy array you will use for\n",
    "   training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a new dataframe/numpy array with only the 2 features Sunshine and Pressure3pm\n",
    "# You should replace this dummy with the actual one you create\n",
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "X = pd.DataFrame(data=d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Determine number of missing values in Sunshine and Pressuer3pm features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a simple imputer to fill in missing values with mean value of attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Impute missing values and fill them in with the mean of the attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Confirm that there are no longer any missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test that you have correctly imputed the missing values with the mean, your new `X` dataframe will be passed to a test function\n",
    "and doctests performed to check that the imputation looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in task2_feature_tests\n",
      "Trying:\n",
      "    ndim, shape, columns, na_sum, description = task2_feature_tests(X)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    ndim\n",
      "Expecting:\n",
      "    2\n",
      "ok\n",
      "Trying:\n",
      "    shape\n",
      "Expecting:\n",
      "    (366, 2)\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2featuretests.py\", line 32, in task2_feature_tests\n",
      "Failed example:\n",
      "    shape\n",
      "Expected:\n",
      "    (366, 2)\n",
      "Got:\n",
      "    (2, 2)\n",
      "Trying:\n",
      "    columns\n",
      "Expecting:\n",
      "    Index(['Sunshine', 'Pressure3pm'], dtype='object')\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2featuretests.py\", line 34, in task2_feature_tests\n",
      "Failed example:\n",
      "    columns\n",
      "Expected:\n",
      "    Index(['Sunshine', 'Pressure3pm'], dtype='object')\n",
      "Got:\n",
      "    Index(['col1', 'col2'], dtype='object')\n",
      "Trying:\n",
      "    na_sum\n",
      "Expecting:\n",
      "    Sunshine       0\n",
      "    Pressure3pm    0\n",
      "    dtype: int64\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2featuretests.py\", line 36, in task2_feature_tests\n",
      "Failed example:\n",
      "    na_sum\n",
      "Expected:\n",
      "    Sunshine       0\n",
      "    Pressure3pm    0\n",
      "    dtype: int64\n",
      "Got:\n",
      "    col1    0\n",
      "    col2    0\n",
      "    dtype: int64\n",
      "Trying:\n",
      "    description\n",
      "Expecting:\n",
      "             Sunshine  Pressure3pm\n",
      "    count  366.000000   366.000000\n",
      "    mean     7.909366  1016.810383\n",
      "    std      3.467180     6.469422\n",
      "    min      0.000000   996.800000\n",
      "    25%      6.000000  1012.800000\n",
      "    50%      8.600000  1017.400000\n",
      "    75%     10.500000  1021.475000\n",
      "    max     13.600000  1033.200000\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2featuretests.py\", line 40, in task2_feature_tests\n",
      "Failed example:\n",
      "    description\n",
      "Expected:\n",
      "             Sunshine  Pressure3pm\n",
      "    count  366.000000   366.000000\n",
      "    mean     7.909366  1016.810383\n",
      "    std      3.467180     6.469422\n",
      "    min      0.000000   996.800000\n",
      "    25%      6.000000  1012.800000\n",
      "    50%      8.600000  1017.400000\n",
      "    75%     10.500000  1021.475000\n",
      "    max     13.600000  1033.200000\n",
      "Got:\n",
      "               col1      col2\n",
      "    count  2.000000  2.000000\n",
      "    mean   1.500000  3.500000\n",
      "    std    0.707107  0.707107\n",
      "    min    1.000000  3.000000\n",
      "    25%    1.250000  3.250000\n",
      "    50%    1.500000  3.500000\n",
      "    75%    1.750000  3.750000\n",
      "    max    2.000000  4.000000\n"
     ]
    }
   ],
   "source": [
    "# For this test, you just need to create the X features dataframe correctly as\n",
    "# described before it is tested here\n",
    "ndim, shape, columns, na_sum, description = task2_feature_tests(X)\n",
    "\n",
    "# run the doc tests so you can see the imputed missing values have been done correctly\n",
    "run_doctests(task2_feature_tests, globals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features number of dimensions:  2\n",
      "Features shape               :  (2, 2)\n",
      "Features columns: \n",
      "Index(['col1', 'col2'], dtype='object')\n",
      "Features na sums: \n",
      "col1    0\n",
      "col2    0\n",
      "dtype: int64\n",
      "Features description: \n",
      "           col1      col2\n",
      "count  2.000000  2.000000\n",
      "mean   1.500000  3.500000\n",
      "std    0.707107  0.707107\n",
      "min    1.000000  3.000000\n",
      "25%    1.250000  3.250000\n",
      "50%    1.500000  3.500000\n",
      "75%    1.750000  3.750000\n",
      "max    2.000000  4.000000\n"
     ]
    }
   ],
   "source": [
    "# you shouldn't have to do anything here, the \n",
    "# properties of your features dataframe are displayed \n",
    "# and should match the expected propertes tested by\n",
    "# the previous doctests\n",
    "print('Features number of dimensions: ', ndim)\n",
    "print('Features shape               : ', shape)\n",
    "print('Features columns: ')\n",
    "print(columns)\n",
    "print('Features na sums: ')\n",
    "print(na_sum)\n",
    "print('Features description: ')\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Binary Classification Task\n",
    "\n",
    "We will use the attributes `Sunshine` and `Pressure3pm` to try and build a binary classifier to predict\n",
    "the rain tomorrow binary label.  First of all lets visualize the task.  Create a plot that:\n",
    "\n",
    "1. Plot the `Sunshine` attribute as the x axis variable, and the 'Pressure3pm' attribute\n",
    "   for the y axis, make sure this is a scatter plot.\n",
    "2. Use shape and/or color to provide a label for each point.  Plot all points on the figure\n",
    "   where rain tomorrow is yes using a shape/color, then plot all the points for no using a\n",
    "   different shape/color.\n",
    "3. Make sure that you create a legend that identifies the point color/shape chose for your yes/no\n",
    "   category.\n",
    "4. Label your x and y axis appropriately for the attributes you plotted on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your plot here that\n",
    "# 1. scatter plot Sunshine as x axis variable and  as y axis variable\n",
    "# 2. perform separate plots for samples where rain tomorrow is yes, vs. where rain tomorrow is no\n",
    "#    use color/shape to differentiate these two categories in the plot\n",
    "# 3. create a legend that identifies rain tomorrow yes/no points in figure\n",
    "# 4. make sure you label your axes and add any other useful information to the figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier using Scikit-learn LogisticRegression\n",
    "\n",
    "Despite its name, the `LogisticRegression` method and object in scikit-learn is used\n",
    "for classification tasks.  Create and fit a Logistic Regression to the `Sunshine` and\n",
    "`Pressure3pm` features.  Perform the following tasks\n",
    "\n",
    "1. Create a `LogisticRegression` using scikit-learn framework.  To make the decision boundary\n",
    "   easier to visualize, use the following parameters when you create this object:\n",
    "   `solver='lbfgs', C=500.0`.  These parameters also will produce a model that is almos the same as the\n",
    "   one that the `statsmodel` classifier will produce.\n",
    "   - You need to implement the creation of the LogisticRegression model in the `task2_sklearn()` function (found in `src/Task2sklearn.py`.  This function should fit\n",
    "     the described model and reutrn it along with the fitted `intercept, slopes, accuracy` values in order\n",
    "     to pass all of the doctests that are performed.\n",
    "   - Fit the logistic regression model to the `Sunshine` and `Pressure3pm` attributes.  Use the X inputs\n",
    "     you created before with missing values filled in. You should already have the\n",
    "     y/labels created for the binary classes from before.\n",
    "   - Extract and return the intercept and model coefficients found for the fitted logistic regression.\n",
    "   - Extract and return the accuracy that this model achieves on all of the data you fit the model with.\n",
    "3. Display a confusion matrix of the performance of this model on all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in task2_sklearn\n",
      "Trying:\n",
      "    from AssgUtils import isclose\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    model, intercept, slopes, accuracy = task2_sklearn(X, y)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    isclose(intercept[0], 186.590648)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2sklearn.py\", line 32, in task2_sklearn\n",
      "Failed example:\n",
      "    isclose(intercept[0], 186.590648)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 186.590648 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(slopes[0][0], -0.320885)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2sklearn.py\", line 34, in task2_sklearn\n",
      "Failed example:\n",
      "    isclose(slopes[0][0], -0.320885)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected -0.320885 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(slopes[0][1], -0.183120)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2sklearn.py\", line 36, in task2_sklearn\n",
      "Failed example:\n",
      "    isclose(slopes[0][1], -0.183120)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected -0.183120 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(accuracy, 0.863388)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2sklearn.py\", line 38, in task2_sklearn\n",
      "Failed example:\n",
      "    isclose(accuracy, 0.863388)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 0.863388 but actual value 0.000000'\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a LogisticRegression model, fit and extract and return the parameters to be tested\n",
    "\n",
    "# your work should go into the src/Task2sklearn function named task2_sklearn()\n",
    "# This cell must not be removed or modified, it calls your function to create a model and\n",
    "# return the fitted parameters from the regression, and it runs doctests to see if your\n",
    "# model fit matches the expected fit you should get\n",
    "model, intercept, slopes, accuracy = task2_sklearn(X, y)\n",
    "\n",
    "# run the doc tests so you can see if your fitted model got the expected results\n",
    "# if any of these tests do not pass (don't get ok result) you have done something\n",
    "# wrong in creating your data and/or fitting your model and extracting the\n",
    "# fit parameters\n",
    "run_doctests(task2_sklearn, globals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept:  0.0\n",
      "Sunshine and Pressure3pm coefficients: [0. 0.]\n",
      "Model accuracy:  0\n"
     ]
    }
   ],
   "source": [
    "# The parameters returned from your function, should match and pass the expected\n",
    "# results in the doctests\n",
    "print('intercept: ', intercept[0])\n",
    "print('Sunshine and Pressure3pm coefficients:', slopes[0])\n",
    "print('Model accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Display a confusion matrix of the performance of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Classifier Decision Boundary\n",
    "\n",
    "When a classification model is fit to a set of binary data, it will determine a\n",
    "decision boundary.  On one side of this boundary, it predicts 'no'/'false', and on\n",
    "the other side it predicts 'yes'/'true'.\n",
    "\n",
    "You can visualize the decision boundary created by your logistic regression model.\n",
    "The slope and intercept coefficients you should have displayed above will describe\n",
    "the decision boundary line that was fit by the logistic regression.  When we plotted\n",
    "your data, you should have used Sunshine as the x axis values, and Pressure3pm as the\n",
    "y axis values.  The logistic regression model should have given you 1 intercept and 2 coefficients.\n",
    "The model of the decision boundary line is thus:\n",
    "\n",
    "\\begin{equation}\n",
    "0 = \\text{intercept} + \\text{coef}_0 \\times \\text{Sunshine} + \\text{coef}_1 \\times \\text{Pressure3pm}\n",
    "\\end{equation}\n",
    "\n",
    "or\n",
    "\n",
    "\\begin{equation}\n",
    "0 = b + \\theta_0  x + \\theta_1  y\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Remember that we use Sunshine as our x values and Pressure3pm as our y values.  We can substitute those names\n",
    "and then solve for y to get the following expression:\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\frac{-(b + \\theta_0 x)}{\\theta_1}\n",
    "\\end{equation}\n",
    "\n",
    "This equation allows you to determine the decision boundary line, given the intercept ($b$) of your\n",
    "model and the two fitted coefficients $\\theta_0 \\theta_1$.  For example, to determine the line, you can\n",
    "plot 2 points. The x axis Sunshine ranges from 0 to 14, so you could determine the y (Pressure3pm) location\n",
    "of the decision boundary at those 2 points and draw a line on the figure to visualize the decision boundary.\n",
    "\n",
    "You thus need to perform the following tasks to visualize the decision boundary that your fitted\n",
    "logistic regression model found:\n",
    "\n",
    "1. Replot your scatter plot figure from before of the Sunshine vs. Pressure3pm points using different markers\n",
    "   for the yes rain / no rain.\n",
    "2. Using the intercept and coefficient of your model, determine 2 points on the decision boundary line.  Add\n",
    "   this line to the figure.\n",
    "3. Make sure your legend includes a label for the decision boundary line.  Make sure axes are labeled\n",
    "   and legend identifies yes, no markers and the decision boundary line.\n",
    "\n",
    "Your resulting figure should look as close to the following as possible.  You should get the shown\n",
    "decision boundary line if you use the parameters shown for your logistic regression:\n",
    "\n",
    "![Logistic Classification Decision Boundary](../figures/assg-02-decision-boundary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your scatter plot here and plot the decision boundary on the plot to match\n",
    "# the figure above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier using statsmodel Logit\n",
    "\n",
    "We will also demonstrate building a binary classifier using the statsmodel library.\n",
    "Perform the following:\n",
    "\n",
    "1. Create a statsmodel Logit instance and fit it to your two features  and binary category labels.\n",
    "   Remember that the api for statsmodel reverses the order of the inputs and the labels when fitting.\n",
    "   Do not change any of the default metaparamters of the Logit, use the default settings for this model.\n",
    "   - You need to implement the creation of the statsmodel logiistic regression model\n",
    "     in the `task2_statsmodel()` function (found in `src/Task2statsmodel.py`).\n",
    "   - This function should fit the described model and reutrn it along with the fitted `params, accuracy` values\n",
    "     in order to pass all of the doctests that are performed.\n",
    "   - Fit the logistic regression model to the Sunshine and Pressure3pm attributes. Use the X inputs you created before with missing values filled in.\n",
    "     You should already have the y/labels created for the binary classes from before.\n",
    "   - You should pass in the `X` unmodified, but don't forget that you need to add a dummy constant term\n",
    "     to the features array to be used by `statsmodel`\n",
    "   - Extract and return the intercept and model parameters found for the fitted logistic regression.\n",
    "   - Extract and return the accuracy that this model achieves on all of the data you fit the model with.\n",
    "2. Display a summary of the fitted model obtained by the statsmodel Logit\n",
    "3. Compare results from statsmodel and scikit learn.  Did they get an equivalent model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in task2_statsmodel\n",
      "Trying:\n",
      "    from AssgUtils import isclose\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    model, params, accuracy = task2_statsmodel(y, X)\n",
      "Expecting:\n",
      "    Optimization terminated successfully.\n",
      "             Current function value: 0.324586\n",
      "             Iterations 7\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2statsmodel.py\", line 33, in task2_statsmodel\n",
      "Failed example:\n",
      "    model, params, accuracy = task2_statsmodel(y, X)\n",
      "Expected:\n",
      "    Optimization terminated successfully.\n",
      "             Current function value: 0.324586\n",
      "             Iterations 7\n",
      "Got nothing\n",
      "Trying:\n",
      "    isclose(params['const'], 186.59040174670466)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2statsmodel.py\", line 39, in task2_statsmodel\n",
      "Failed example:\n",
      "    isclose(params['const'], 186.59040174670466)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 186.590402 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(params['Sunshine'], -0.3208828310913976)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2statsmodel.py\", line 41, in task2_statsmodel\n",
      "Failed example:\n",
      "    isclose(params['Sunshine'], -0.3208828310913976)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected -0.320883 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(params['Pressure3pm'], -0.18311988277396155)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2statsmodel.py\", line 43, in task2_statsmodel\n",
      "Failed example:\n",
      "    isclose(params['Pressure3pm'], -0.18311988277396155)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected -0.183120 but actual value 0.000000'\n",
      "Trying:\n",
      "    isclose(accuracy, 0.8633879781420765)\n",
      "Expecting:\n",
      "    True\n",
      "**********************************************************************\n",
      "File \"/workspaces/assg02/notebooks/../src/Task2statsmodel.py\", line 45, in task2_statsmodel\n",
      "Failed example:\n",
      "    isclose(accuracy, 0.8633879781420765)\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    'False: expected 0.863388 but actual value 0.000000'\n"
     ]
    }
   ],
   "source": [
    "# 2. Create Logit instance and fit it to the data, make sure to add dummy feature to X, and extract\n",
    "# and return the model parameters\n",
    "\n",
    "# your work should go into the src/Task2statsmodel function named task2_statsmodel()\n",
    "# This cell must not be removed or modified, it calls your function to create a model and\n",
    "# return the fitted parameters from the regression, and it runs doctests to see if your\n",
    "# model fit matches the expected fit you should get\n",
    "model, params, accuracy = task2_statsmodel(y, X)\n",
    "\n",
    "# run the doc tests so you can see if your fitted model got the expected results\n",
    "# if any of these tests do not pass (don't get ok result) you have done something\n",
    "# wrong in creating your data and/or fitting your model and extracting the\n",
    "# fit parameters\n",
    "run_doctests(task2_statsmodel, globals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Display a summary of the statsmodel fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Compare accuracy, you can demonstrate or change/add a markdown cell and discuss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the Results**\n",
    "\n",
    "Discuss and compare the two classifiers.  Are the parameters obtained the same?  Do they\n",
    "achieve the same accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Improve the Classifier\n",
    "--------\n",
    "\n",
    "I may give a point or to back of missed points on the assignment for doing the following.\n",
    "We only used 2 features in our classifier because that makes it possible to visualize the\n",
    "decision boundary.  However, the RISK_MM feature is highly correlated with the rain tomorrow\n",
    "binary label we are trying to predict.\n",
    "\n",
    "Create a logistic regression model (you can use either scikit-learn or statsmodel or both).  But this\n",
    "time train with the RISK_MM, along with the other two features we used before.  Report accuracy and confusion matrix for this model.  If interested, you can look at the correlation of other features\n",
    "given in the dataset, and try adding others besides these 3 to see if you can get further improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra work here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
